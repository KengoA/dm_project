{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:34:10.163267Z",
     "start_time": "2017-11-12T22:34:10.155412Z"
    },
    "collapsed": true
   },
   "source": [
    "## PCA + Standard Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:55:42.384645Z",
     "start_time": "2017-11-12T22:55:42.378450Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import decomposition, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:55:43.282086Z",
     "start_time": "2017-11-12T22:55:43.012859Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the csv file\n",
    "df = pd.read_csv('data/labels.csv')\n",
    "\n",
    "#Sort by frequency and extract top 10\n",
    "dist = df.groupby('breed').count().rename(columns={'id':'freq'})\n",
    "most_common = dist.sort_values(by='freq',ascending=False)\n",
    "top_10 = [i for i in most_common[:10].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:55:44.011295Z",
     "start_time": "2017-11-12T22:55:43.982897Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select rows with breeds in top 10\n",
    "df = df[df['breed'].isin(top_10)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "data_length = len(df)\n",
    "\n",
    "#Define dictionaries to convert between class value and the breed name\n",
    "breed = top_10\n",
    "class_length = len(breed)\n",
    "class_to_num = dict(zip(breed, range(class_length)))\n",
    "num_to_class = dict(zip(range(class_length), breed))\n",
    "\n",
    "#Set the dimension at 150\n",
    "dim = 150\n",
    "\n",
    "X = np.zeros((data_length, dim, dim, 3),dtype=np.uint8)\n",
    "y = np.zeros((data_length, class_length),dtype=np.uint8)\n",
    "\n",
    "X_flat = np.zeros((data_length, dim*dim*3),dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:55:52.438069Z",
     "start_time": "2017-11-12T22:55:44.929098Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1141/1141 [00:04<00:00, 254.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data_length)):\n",
    "    #Read in the image\n",
    "    image = cv2.imread('data/train/{}.jpg'.format(df['id'][i]))\n",
    "    #Resize\n",
    "    resized = cv2.resize(image,(dim, dim))\n",
    "    #Remove single-dimensional entries\n",
    "    np.squeeze(np.array(resized).astype(np.float32))        \n",
    "    #Flatten\n",
    "    flat_arr = resized.ravel()\n",
    "\n",
    "    X_flat[i] = flat_arr\n",
    "    #Increment the categorical value for the corresponding breed by 1\n",
    "    y[i][class_to_num[df['breed'][i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:55:57.867812Z",
     "start_time": "2017-11-12T22:55:57.857774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1141, 67500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape\n",
    "X_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:55:58.600908Z",
     "start_time": "2017-11-12T22:55:58.594839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components_ = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:56:16.783350Z",
     "start_time": "2017-11-12T22:55:59.387839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=n_components_)\n",
    "#pca = decomposition.TruncatedSVD(n_components=n_components_, algorithm='randomized')\n",
    "pca.fit(X_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:56:22.525448Z",
     "start_time": "2017-11-12T22:56:22.518653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286405952151277"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how much variance of the original data is explained by the components\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:56:54.383804Z",
     "start_time": "2017-11-12T22:56:26.531362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1141/1141 [00:15<00:00, 73.44it/s]\n"
     ]
    }
   ],
   "source": [
    "X_reduced = np.zeros((X_flat.shape[0], n_components_),dtype=np.float32)\n",
    "\n",
    "for i in tqdm(range(len(X_flat))):\n",
    "    pca_arr = pca.transform(X_flat[i].reshape(1, -1))\n",
    "    X_reduced[i] = pca_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:56:55.352545Z",
     "start_time": "2017-11-12T22:56:55.343934Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/features/pca_train.npy',X_reduced)\n",
    "X_reduced = np.load('data/features/pca_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:56:58.833457Z",
     "start_time": "2017-11-12T22:56:58.789730Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_categorical = np.array([None]*data_length)\n",
    "for i in range(len(y)):\n",
    "    y_categorical[i] = df['breed'][i]\n",
    "\n",
    "y_categorical = [class_to_num[i] for i in y_categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:57:27.587583Z",
     "start_time": "2017-11-12T22:57:27.577604Z"
    }
   },
   "outputs": [],
   "source": [
    "#Split the data into train and test, then normalise them\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y_categorical, test_size=0.2) #train_test_split(X_reduced, y_categorical, test_size=0.2)#train_test_split(X_flat, y_categorical, test_size=0.2)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 200.0\n",
    "X_test /= 200.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "\n",
    "Add more classifiers and check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-12T22:57:28.747190Z",
     "start_time": "2017-11-12T22:57:28.737801Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = SVC(C = 0.000125,\n",
    "              kernel = 'linear',\n",
    "              probability = True,\n",
    "              verbose = True)\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors = 34)\n",
    "\n",
    "clf_dt = DecisionTreeClassifier(max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-12T23:01:21.181Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.29473684210526313, total=16.5min\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.2553191489361702, total=16.5min\n",
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.3191489361702128, total=16.5min\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.3333333333333333, total=16.6min\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.25, total=16.9min\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed: 38.0min remaining: 38.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.21978021978021978, total=16.9min\n",
      "[CV] C=0.000125, kernel=linear, probability=True, verbose=True .......\n",
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.26373626373626374, total=16.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed: 38.2min remaining: 16.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.29213483146067415, total=17.1min\n",
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.26436781609195403, total= 6.9min\n",
      "[LibSVM][CV]  C=0.000125, kernel=linear, probability=True, verbose=True, score=0.3488372093023256, total= 6.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 45.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]SVC(C=0.000125, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=True)\n",
      "0.28399122807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Find the best parameters with GridSearchCV\n",
    "cs = [0.000125]#[1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2]\n",
    "gammas = ['auto']#[0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000]\n",
    "kernels = ['linear']#, 'poly', 'sigmoid', 'rbf']\n",
    "\n",
    "parameters_svc = {'C': cs, #0.000125\n",
    "              'kernel': kernels,\n",
    "              'probability': [True],\n",
    "              'verbose': [True]\n",
    "              }\n",
    "grid_svc = GridSearchCV(error_score='accuracy_score', estimator=clf_svc, param_grid=parameters_svc, cv=10 , verbose=10, n_jobs=-1)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "clf_svc = grid_svc.best_estimator_\n",
    "print(grid_svc.best_estimator_)\n",
    "print(grid_svc.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data/accuracies/grid_accuracies_svc.csv', 'wt') as csvfile:\n",
    "    csvfile.truncate()\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerow(['mean_fit_time', 'param_C', 'param_kernel', 'mean_test_score'])\n",
    "    #for results in grid_svc.cv_results_:\n",
    "        #print(results)\n",
    "    for score in range(len(cs)*len(kernels)*len(gammas)):\n",
    "        writer.writerow([grid_svc.cv_results_['mean_fit_time'][score], \n",
    "                            grid_svc.cv_results_['param_C'][score], \n",
    "                            grid_svc.cv_results_['param_kernel'][score], \n",
    "                            grid_svc.cv_results_['mean_test_score'][score]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscores_mean = grid_svc.cv_results_[\\'mean_test_score\\']\\nscores_mean = np.array(scores_mean).reshape(len(kernels),len(cs))\\n\\nscores_sd = grid_svc.cv_results_[\\'std_test_score\\']\\nscores_sd = np.array(scores_sd).reshape(len(kernels),len(cs))\\n\\n# Plot Grid search scores\\n_, ax = plt.subplots(1,1)\\n\\n# Param1 is the X-axis, Param 2 is represented as a different curve (color line)\\nfor idx, val in enumerate(kernels):\\n    ax.plot(cs, scores_mean[idx,:], \\'-o\\', label= \\'kernels\\' + \\': \\' + str(val))\\n\\nax.set_title(\"Grid Search Scores\", fontsize=20, fontweight=\\'bold\\')\\nax.set_xlabel(\\'C\\', fontsize=16)\\nax.set_ylabel(\\'CV Average Score\\', fontsize=16)\\nax.legend(loc=\"best\", fontsize=15)\\nax.grid(\\'on\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "scores_mean = grid_svc.cv_results_['mean_test_score']\n",
    "scores_mean = np.array(scores_mean).reshape(len(kernels),len(cs))\n",
    "\n",
    "scores_sd = grid_svc.cv_results_['std_test_score']\n",
    "scores_sd = np.array(scores_sd).reshape(len(kernels),len(cs))\n",
    "\n",
    "# Plot Grid search scores\n",
    "_, ax = plt.subplots(1,1)\n",
    "\n",
    "# Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "for idx, val in enumerate(kernels):\n",
    "    ax.plot(cs, scores_mean[idx,:], '-o', label= 'kernels' + ': ' + str(val))\n",
    "\n",
    "ax.set_title(\"Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "ax.set_xlabel('C', fontsize=16)\n",
    "ax.set_ylabel('CV Average Score', fontsize=16)\n",
    "ax.legend(loc=\"best\", fontsize=15)\n",
    "ax.grid('on')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "0.198464912281\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Find the best parameters with GridSearchCV\n",
    "max_depths = [5]#[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] #[3]#\n",
    "min_samples_splits = [2]#[2, 3, 4, 5, 6] #[2]#\n",
    "min_samples_leafs = [1]#[1, 2, 3, 4, 5] #[1]#\n",
    "criterions = ['gini']#['entropy','gini'] #['gini']#\n",
    "max_features = [None] #['auto', 'log2', None]\n",
    "max_leaf_nodes = [None]\n",
    "\n",
    "\n",
    "\n",
    "parameters_dt = {'max_depth': max_depths,\n",
    "                 'min_samples_split': min_samples_splits,\n",
    "                 'min_samples_leaf': min_samples_leafs,\n",
    "                 'criterion': criterions, \n",
    "                 'max_features': max_features,\n",
    "                 'max_leaf_nodes': max_leaf_nodes,\n",
    "              }\n",
    "grid_dt = GridSearchCV(error_score='accuracy_score', estimator=clf_dt, param_grid=parameters_dt, cv=10 , verbose=1, n_jobs=-1)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "clf_dt = grid_dt.best_estimator_\n",
    "print(grid_dt.best_estimator_)\n",
    "print(grid_dt.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data/accuracies/grid_accuracies_dt.csv', 'wt') as csvfile:\n",
    "    csvfile.truncate()\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerow(['mean_fit_time', 'param_max_depth', 'param_min_samples_split', 'param_min_samples_leaf', 'param_criterion', 'mean_test_score'])\n",
    "    #for results in grid_dt.cv_results_:\n",
    "        #print(results)\n",
    "    for score in range(len(max_depths)*len(min_samples_splits)*len(min_samples_leafs)*len(criterions)*len(max_features)*len(max_leaf_nodes)):\n",
    "        writer.writerow([grid_dt.cv_results_['mean_fit_time'][score], \n",
    "                            grid_dt.cv_results_['param_max_depth'][score], \n",
    "                            grid_dt.cv_results_['param_min_samples_split'][score], \n",
    "                            grid_dt.cv_results_['param_min_samples_leaf'][score], \n",
    "                            grid_dt.cv_results_['param_criterion'][score],                          \n",
    "                            grid_dt.cv_results_['mean_test_score'][score]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=34, p=2,\n",
      "           weights='uniform')\n",
      "0.186403508772\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Find the best parameters with GridSearchCV\n",
    "neighbours = [34]#[n+1 for n in range(50)] #[34]#\n",
    "\n",
    "parameters_knn = {'n_neighbors': neighbours}\n",
    "\n",
    "grid_knn = GridSearchCV(error_score='accuracy_score', estimator=clf_knn, param_grid=parameters_knn, cv=10 , verbose=1, n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "clf_knn = grid_knn.best_estimator_\n",
    "print(grid_knn.best_estimator_)\n",
    "print(grid_knn.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data/accuracies/grid_accuracies_knn.csv', 'wt') as csvfile:\n",
    "    csvfile.truncate()\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerow(['mean_fit_time', 'param_n_neighbors', 'mean_test_score'])\n",
    "    #for results in grid_knn.cv_results_:\n",
    "        #print(results)\n",
    "    for score in range(len(neighbours)):\n",
    "        writer.writerow([grid_knn.cv_results_['mean_fit_time'][score], \n",
    "                            grid_knn.cv_results_['param_n_neighbors'][score], \n",
    "                            grid_knn.cv_results_['mean_test_score'][score]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Log Loss SVC :\t1.9903648556\n",
      "Accuracy Score SVC :\t0.266375545852\n",
      "Log Loss DT :\t\t6.49124885138\n",
      "Accuracy Score DT :\t0.17903930131\n",
      "Log Loss KNN :\t\t3.13283876867\n",
      "Accuracy Score KNN :\t0.192139737991\n"
     ]
    }
   ],
   "source": [
    "# fitting svc\n",
    "clf_svc.fit(X_train, y_train)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "  \n",
    "#prediction with grid parameters         \n",
    "prediction_svc = np.array(clf_svc.predict(X_test))\n",
    "prediction_proba_svc = np.array(clf_svc.predict_proba(X_test))\n",
    "\n",
    "prediction_dt = np.array(clf_dt.predict(X_test))\n",
    "prediction_proba_dt = np.array(clf_dt.predict_proba(X_test))  \n",
    "\n",
    "prediction_knn = np.array(clf_knn.predict(X_test))\n",
    "prediction_proba_knn = np.array(clf_knn.predict_proba(X_test))   \n",
    "        \n",
    "#calculate accuracy\n",
    "path_name = 'data/accuracies/accuracy_and_logloss.txt'\n",
    "    \n",
    "loss_svc = log_loss(y_test, prediction_proba_svc, labels=[class_to_num[b] for b in breed])\n",
    "accuracy_svc = accuracy_score(y_test, prediction_svc)\n",
    "\n",
    "    \n",
    "loss_dt = log_loss(y_test, prediction_proba_dt, labels=[class_to_num[b] for b in breed])\n",
    "accuracy_dt = accuracy_score(y_test, prediction_dt)\n",
    "\n",
    "loss_knn = log_loss(y_test, prediction_proba_knn, labels=[class_to_num[b] for b in breed])\n",
    "accuracy_knn = accuracy_score(y_test, prediction_knn)\n",
    "\n",
    "with open(path_name, 'a') as file:\n",
    "    file.truncate()\n",
    "    file.write('Log Loss SVC '+ ':\\t\\t\\t' + str(loss_svc)  + '\\n')\n",
    "    print('Log Loss SVC '+ ':\\t' + str(loss_svc))\n",
    "    file.write('Accuracy Score SVC '+ ':\\t' + str(accuracy_svc) + '\\n')\n",
    "    print('Accuracy Score SVC '+ ':\\t' + str(accuracy_svc))\n",
    "    \n",
    "    file.write('Log Loss DT '+ ':\\t\\t\\t' + str(loss_dt)  + '\\n')\n",
    "    print('Log Loss DT '+ ':\\t\\t' + str(loss_dt))\n",
    "    file.write('Accuracy Score DT '+ ':\\t\\t' + str(accuracy_dt) + '\\n')\n",
    "    print('Accuracy Score DT '+ ':\\t' + str(accuracy_dt))\n",
    "    \n",
    "    file.write('Log Loss KNN '+ ':\\t\\t\\t' + str(loss_knn)  + '\\n')\n",
    "    print('Log Loss KNN '+ ':\\t\\t' + str(loss_knn))\n",
    "    file.write('Accuracy Score KNN '+ ':\\t' + str(accuracy_knn) + '\\n')\n",
    "    print('Accuracy Score KNN '+ ':\\t' + str(accuracy_knn))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
