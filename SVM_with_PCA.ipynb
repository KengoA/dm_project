{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn import datasets, metrics, preprocessing, decomposition\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "X_labels = pd.read_csv('dataset/labels.csv')\n",
    "\n",
    "sample_submission = pd.read_csv('dataset/sample_submission.csv')\n",
    "y_data_names = sample_submission['id']\n",
    "\n",
    "train_data_length = len(X_labels)\n",
    "test_data_length = len(y_data_names)\n",
    "breed = set(X_labels['breed'])\n",
    "\n",
    "class_length = len(breed)\n",
    "class_to_num = dict(zip(breed, range(class_length)))\n",
    "num_to_class = dict(zip(range(class_length), breed))\n",
    "\n",
    "width = 299\n",
    "\n",
    "X_train = np.zeros((train_data_length, width, width, 3),dtype=np.uint8)\n",
    "X_test = np.zeros((test_data_length, width, width, 3),dtype=np.uint8)\n",
    "\n",
    "y_train = np.zeros((train_data_length, class_length),dtype=np.uint8)\n",
    "\n",
    "\n",
    "X_test_flat = np.zeros((test_data_length, width*width*3),dtype=np.uint8)\n",
    "X_train_flat = np.zeros((train_data_length, width*width*3),dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:54<00:00, 187.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(train_data_length)):   \n",
    "    image = cv2.imread('dataset/train/{}.jpg'.format(X_labels['id'][i]))\n",
    "    resized = cv2.resize(image,(width, width))\n",
    "    #gray_image = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    xarr = resized\n",
    "    np.squeeze(np.array(resized).astype(np.float32))        \n",
    "    \n",
    "    flat_arr = xarr.ravel()\n",
    "\n",
    "    #X_train[i] = xarr\n",
    "    X_test_flat[i] = flat_arr\n",
    "    \n",
    "    y_train[i][class_to_num[X_labels['breed'][i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:52<00:00, 195.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(train_data_length)):   \n",
    "    image = cv2.imread('dataset/test/{}.jpg'.format(y_data_names[i]))\n",
    "    resized = cv2.resize(image,(width, width))\n",
    "    #gray_image = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    xarr = resized\n",
    "    np.squeeze(np.array(resized).astype(np.float32))        \n",
    "    \n",
    "    flat_arr = xarr.ravel()\n",
    "   \n",
    "    #X_test[i] = xarr\n",
    "    X_test_flat[i] = flat_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_flat = X_train_flat.astype(int)\n",
    "X_test_flat = X_test_flat.astype(int)\n",
    "\n",
    "pca = decomposition.PCA(n_components=int(len(X_train_flat[0])), svd_solver='randomized')\n",
    "pca.fit(X_test_flat[:int(len(X_train_flat)//5)])\n",
    "\n",
    "for i in tqdm(range(len(X_train_flat))):\n",
    "    pca_arr = pca.transform(X_train_flat[i].reshape(1, -1))\n",
    "    X_train_flat[i] = pca_arr\n",
    "    \n",
    "for i in tqdm(range(len(X_test_flat))):\n",
    "    pca_arr = pca.transform(X_test_flat[i].reshape(1, -1))\n",
    "    X_test_flat[i] = pca_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_categorical = [None] * train_data_length\n",
    "y_train_categorical = np.array(y_train_categorical)\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    y_train_categorical[i] = X_labels['breed'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(X_labels['breed'])\n",
    "\n",
    "print(y_train_categorical[1])\n",
    "y_train_categorical = le.transform(y_train_categorical) \n",
    "print(y_train_categorical[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#svm_classifier = SVC()\n",
    "\n",
    "\n",
    "#param_grid = {'gamma': [10, 1, 0.1, 0.01], \n",
    "#                'C': [1, 10, 100, 1000],\n",
    "#                'kernel': ['rbf', 'linear'],\n",
    "#                'probability': [True],\n",
    "#                'verbose': [True]}\n",
    "        \n",
    "#grid = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, verbose = 10, n_jobs=-1)      \n",
    "#grid.fit(X_train_flat, y_train_categorical)\n",
    "\n",
    "#print(grid)\n",
    "#print(grid.best_estimator_) \n",
    "        \n",
    "#file = open('SVM_params.txt', 'a')\n",
    "#file.write(str(grid))\n",
    "#file.write('\\n')\n",
    "#file.write(str(grid.best_estimator_))\n",
    "#file.write('\\n')\n",
    "#file.close() \n",
    "                \n",
    "#svm_classifier = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='linear', C=2.5, gamma=5, probability=True, verbose=True)\n",
    "\n",
    "print('START FITTING')\n",
    "svm_classifier.fit(X_train_flat, y_train_categorical)\n",
    "print('END FITTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('START PREDICTING')\n",
    "#prediction = svm_classifier.predict(X_test_flat)\n",
    "#print('END PREDICTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('START PREDICTING PROBABILITY')\n",
    "probability_result = svm_classifier.predict_proba(X_test_flat)\n",
    "print('END PREDICTING PROBABILITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = 'submission_nogray.csv'\n",
    "\n",
    "with open(filename, 'wt') as csvfile:\n",
    "    csvfile.truncate()\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    label_names = []\n",
    "    \n",
    "    label_names.append('id')\n",
    "    for b in breed:\n",
    "        label_names.append(b)\n",
    "        \n",
    "    writer.writerow([label for label in label_names])\n",
    "        \n",
    "    result_row = []    \n",
    "    for i in tqdm(range(len(probability_result))):\n",
    "        result_row.append(y_data_names[i])\n",
    "        \n",
    "        for result in probability_result[i]:\n",
    "            result_row.append(result)\n",
    "        \n",
    "        writer.writerow([result for result in result_row])\n",
    "        \n",
    "        del result_row[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
